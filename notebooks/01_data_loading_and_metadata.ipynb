{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d73beb1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mrrobot/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gzip\n",
    "import os\n",
    "\n",
    "project_dir = '/Users/mrrobot/Projects_/EDA_dashboard_GEO_dataset/data'\n",
    "data_dir = os.path.join(project_dir, 'raw')\n",
    "count_matrix_file = os.path.join(data_dir, 'GSE99254_NSCLC.TCell.S12346.count.txt.gz')\n",
    "counts_df = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e7ff9d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded count matrix with 'symbol' as index:\n",
      "Shape: (23459, 12346)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with gzip.open(count_matrix_file, 'rt') as f:\n",
    "        temp_df = pd.read_csv(f, sep='\\t')\n",
    "        if 'symbol' in temp_df.columns:\n",
    "            counts_df = temp_df.set_index('symbol')\n",
    "            # Assuming the first column after 'symbol' (originally the first actual column) might be 'geneID'\n",
    "            # Or if 'geneID' was the first column name in the file and 'symbol' the second:\n",
    "            if 'geneID' in counts_df.columns and counts_df.columns[0] == 'geneID':\n",
    "                 counts_df = counts_df.drop(columns=['geneID'])\n",
    "            elif counts_df.index.name == 'geneID': # If geneID became index name from first col\n",
    "                 pass # No action needed if 'symbol' successfully became index\n",
    "            print(\"Successfully loaded count matrix with 'symbol' as index:\")\n",
    "            print(f\"Shape: {counts_df.shape}\")\n",
    "            # print(counts_df.iloc[:5, :5]) # Show top-left corner\n",
    "        else:\n",
    "            # Fallback if 'symbol' isn't a column, maybe first column is symbol, second is geneID\n",
    "            # This part might need adjustment based on actual file structure if 'symbol' isn't a header\n",
    "            counts_df = pd.read_csv(count_matrix_file, sep='\\t', index_col=0, compression='gzip')\n",
    "            print(\"Loaded count matrix (assuming first column is gene symbol index):\")\n",
    "            print(f\"Shape: {counts_df.shape}\")\n",
    "            # print(counts_df.iloc[:5, :5])\n",
    "\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Count matrix file not found at {count_matrix_file}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred loading count matrix: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645fbc4c",
   "metadata": {},
   "source": [
    "This is the most crucial step to unlock further analysis with what you have. The cell IDs in your counts_df columns (e.g., NTH10-0616A, TTC1-P0617) contain prefixes that indicate the sample type.\n",
    "\n",
    "NTH: Normal Tissue (adjacent non-tumor, CD4+ T helper like)\n",
    "NTC: Normal Tissue (adjacent non-tumor, CD8+ T cells)\n",
    "TTC: Tumor Tissue (CD8+ T cells)\n",
    "TTH: Tumor Tissue (CD4+ T helper like - assuming this exists, or a similar tumor CD4 prefix)\n",
    "PTC: Peripheral Blood (CD8+ T cells)\n",
    "PTH: Peripheral Blood (CD4+ T helper like)\n",
    "(We might also see NTY, TTY, PTY for regulatory T cells based on initial GEO description)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b37b7cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basic Per-Cell Metadata DataFrame created from cell IDs:\n",
      "Shape: (12346, 3)\n",
      "            sample_type_prefix tissue_origin patient_id\n",
      "NTH10-0616A                NTH   Normal_Lung      0616A\n",
      "NTH11-0616A                NTH   Normal_Lung      0616A\n",
      "NTH15-0616A                NTH   Normal_Lung      0616A\n",
      "NTH17-0616A                NTH   Normal_Lung      0616A\n",
      "NTH2-0616A                 NTH   Normal_Lung      0616A\n",
      "\n",
      "Unique tissue origins found:\n",
      "tissue_origin\n",
      "Tumor_Lung          5971\n",
      "Peripheral_Blood    4260\n",
      "Normal_Lung         2115\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Unique sample type prefixes found:\n",
      "sample_type_prefix\n",
      "TTC    2182\n",
      "TTH    1591\n",
      "PTC    1323\n",
      "PTH    1254\n",
      "TTR    1100\n",
      "NTC     934\n",
      "TTY     892\n",
      "PTR     849\n",
      "PTY     672\n",
      "NTH     655\n",
      "NTY     238\n",
      "PTS     162\n",
      "NTR     149\n",
      "NTS     139\n",
      "T-C     136\n",
      "TTS      70\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "if counts_df is not None:\n",
    "    cell_ids = counts_df.columns.tolist()\n",
    "    \n",
    "    # Create a basic metadata dataframe\n",
    "    basic_metadata_df = pd.DataFrame(index=cell_ids)\n",
    "    \n",
    "    # Extract sample type prefix (first 3 characters)\n",
    "    basic_metadata_df['sample_type_prefix'] = [cell_id[:3] for cell_id in cell_ids]\n",
    "    \n",
    "    # Map prefixes to meaningful tissue origins\n",
    "    # This mapping might need refinement based on exact prefixes in your cell IDs\n",
    "    # and the GEO page description of sample types\n",
    "    prefix_to_origin = {\n",
    "    'NTH': 'Normal_Lung',      # Normal T-helper (CD4+)\n",
    "    'NTC': 'Normal_Lung',      # Normal CD8+\n",
    "    'NTY': 'Normal_Lung',      # Normal Treg (likely CD4+CD25+)\n",
    "    'NTR': 'Normal_Lung',      # Normal Treg (alternative or similar to NTY)\n",
    "    'NTS': 'Normal_Lung',      # Normal T-cell (Stimulated or other specific sort)\n",
    "    'TTC': 'Tumor_Lung',       # Tumor CD8+\n",
    "    'TTH': 'Tumor_Lung',       # Tumor T-helper (CD4+)\n",
    "    'TTY': 'Tumor_Lung',       # Tumor Treg (likely CD4+CD25+)\n",
    "    'TTR': 'Tumor_Lung',       # Tumor Treg (alternative or similar to TTY)\n",
    "    'TTS': 'Tumor_Lung',       # Tumor T-cell (Stimulated or other specific sort)\n",
    "    'PTC': 'Peripheral_Blood', # Peripheral CD8+\n",
    "    'PTH': 'Peripheral_Blood', # Peripheral T-helper (CD4+)\n",
    "    'PTY': 'Peripheral_Blood', # Peripheral Treg (likely CD4+CD25+)\n",
    "    'PTR': 'Peripheral_Blood', # Peripheral Treg (alternative or similar to PTY)\n",
    "    'PTS': 'Peripheral_Blood', # Peripheral T-cell (Stimulated or other specific sort)\n",
    "    'T-C': 'Tumor_Lung'        # This is a bit ambiguous. Assuming \"Tumor-Cell\" or \"Tumor-Cluster\".\n",
    "                               # If its origin is unclear after checking some cell IDs, \n",
    "                               # you might map it to 'Unknown' or investigate further.\n",
    "                               # For now, if it's consistently from tumor samples, this is a starting point.\n",
    "}\n",
    "    basic_metadata_df['tissue_origin'] = basic_metadata_df['sample_type_prefix'].map(prefix_to_origin)\n",
    "    \n",
    "    # Extract patient ID (example: from 'NTH10-0616A', patient is '0616A' after the hyphen)\n",
    "    # This is an assumption and might need adjustment based on all cell ID formats\n",
    "    def extract_patient_id(cell_id):\n",
    "        parts = cell_id.split('-')\n",
    "        if len(parts) > 1:\n",
    "            return parts[-1] # Takes the part after the last hyphen\n",
    "        return None # Or some default\n",
    "    # A more robust way might be to get the part after the first hyphen or based on a pattern\n",
    "    # For Pxxxx IDs like in some of your cell names, we might need another rule.\n",
    "    # For now, let's make a placeholder for patient ID.\n",
    "    # A fuller solution requires inspecting all unique cell ID patterns.\n",
    "    # The GEO page mentioned Patient IDs like P0617. These are embedded in cell names like 'TTC1-P0617'\n",
    "    \n",
    "    patient_ids = []\n",
    "    for cell_id in cell_ids:\n",
    "        if '-P' in cell_id: # For IDs like TTC1-P0617\n",
    "            patient_ids.append(cell_id.split('-P')[1])\n",
    "        elif '-' in cell_id: # For IDs like NTH10-0616A\n",
    "            patient_ids.append(cell_id.split('-',1)[1]) # content after first hyphen\n",
    "        else:\n",
    "            patient_ids.append('Unknown')\n",
    "    basic_metadata_df['patient_id'] = patient_ids\n",
    "\n",
    "\n",
    "    print(\"\\nBasic Per-Cell Metadata DataFrame created from cell IDs:\")\n",
    "    print(f\"Shape: {basic_metadata_df.shape}\")\n",
    "    print(basic_metadata_df.head())\n",
    "    print(\"\\nUnique tissue origins found:\")\n",
    "    print(basic_metadata_df['tissue_origin'].value_counts(dropna=False))\n",
    "    print(\"\\nUnique sample type prefixes found:\")\n",
    "    print(basic_metadata_df['sample_type_prefix'].value_counts(dropna=False))\n",
    "else:\n",
    "    print(\"counts_df is not loaded, skipping metadata creation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa690e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved raw counts_df to /Users/mrrobot/Projects_/EDA_dashboard_GEO_dataset/data/data/processed/counts_matrix_raw.csv.gz\n",
      "Saved basic_metadata_df to /Users/mrrobot/Projects_/EDA_dashboard_GEO_dataset/data/data/processed/cell_metadata_basic.csv\n"
     ]
    }
   ],
   "source": [
    "# Define paths for processed data\n",
    "processed_data_dir = os.path.join(project_dir, 'data', 'processed')\n",
    "if not os.path.exists(processed_data_dir):\n",
    "    os.makedirs(processed_data_dir) # Create directory if it doesn't exist\n",
    "\n",
    "if counts_df is not None:\n",
    "    counts_df.to_csv(os.path.join(processed_data_dir, 'counts_matrix_raw.csv.gz'), compression='gzip')\n",
    "    print(f\"\\nSaved raw counts_df to {os.path.join(processed_data_dir, 'counts_matrix_raw.csv.gz')}\")\n",
    "\n",
    "if basic_metadata_df is not None:\n",
    "    basic_metadata_df.to_csv(os.path.join(processed_data_dir, 'cell_metadata_basic.csv'))\n",
    "    print(f\"Saved basic_metadata_df to {os.path.join(processed_data_dir, 'cell_metadata_basic.csv')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b01eeaf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
